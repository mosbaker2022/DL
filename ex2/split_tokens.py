# Dictionary that mapps shortenning experssions to standard text
# This helps by reducing the number of out of vocabulary words found in
# text that has a lot of shortened expressions (such as in tweets
split_tokens_dict =  {"ain't": "am not",
                 "aren't": "are not",
                 "can't": "can not",
                 "couldn't": "could not",
                 "didn't": "did not",
                 "doesn't": "does not",
                 "don't": "do not",
                 "everything's": "everything is",
                 "hadn't": "had not",
                 "hasn't": "has not",
                 "haven't": "have not",
                 "he'd": "he would",
                 "he'll": "he will",
                 "he's": "he is",
                 "here's": "here is",
                 "how's": "how is",
                 "i'd": "i would",
                 "i'll": "i will",
                 "i'm": "i am",
                 "i'ma": "i am going to",
                 "i've": "i have",
                 "isn't": "is not",
                 "it'll": "it will",
                 "it's": "it is",
                 "let's": "let us",
                 "life's": "life is",
                 "she'd": "she would",
                 "she'll": "she will",
                 "she's": "she is",
                 "should've": "should have",
                 "shouldn't": "should not",
                 "that'd": "that would",
                 "that'll": "that will",
                 "that's": "that is",
                 "there's": "there is",
                 "they'd": "they would",
                 "they'll": "they will",
                 "they're": "they are",
                 "they've": "they have",
                 "this'll": "this will",
                 "wasn't": "was not",
                 "we'd": "we would",
                 "we'll": "we will",
                 "we're": "we are",
                 "we've": "we have",
                 "what's": "what is",
                 "where's": "where is",
                 "won't": "will not",
                 "would've": "would have",
                 "wouldn't": "would not",
                 "y'all": "you all",
                 "you'd": "you would",
                 "you'll": "you will",
                 "you're": "you are",
                 "you've": "you have"}
def split_token(t):
    if t in split_tokens_dict:
        return split_tokens_dict[t].split(" ")
    else:
        return t